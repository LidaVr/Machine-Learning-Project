{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPBj6gbBw4vXbBQrb5FnUj3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["The purpose of this script is to split the images into 3 sets of data: Train, Test and Validation. Each set will contain random pictures from each category (keeping the same folder structure). Based on the size (7,838 images) of our dataset we decided on using the following ratios: 70%Train, 15%Test, 15%Validation.\n","\n","70% Training: This is the portion of the dataset that our model will learn from. It's important to have a sufficiently large training set to allow the model to generalize well and learn the underlying patterns in the data.\n","\n","15% Testing: The testing set is used to evaluate the model's performance on data it hasn't seen during training. This helps us understand how well our model is likely to perform on new, unseen data.\n","\n","15% Validation: The validation set is used to fine-tune hyperparameters and monitor the model's performance during training. It helps prevent overfitting by allowing us to make adjustments based on validation performance.\n","\n"],"metadata":{"id":"9gFJ2xRGKANW"}},{"cell_type":"code","source":["#Connect to GoogleDrive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b0MrNpkpKA0E","executionInfo":{"status":"ok","timestamp":1692456328401,"user_tz":-180,"elapsed":98618,"user":{"displayName":"Lida Vratsanou","userId":"08330597830077843111"}},"outputId":"bbcaad60-24c9-44a2-f14d-bf5f8dbef5ba"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["#Install necessary libraries\n","import os\n","import cv2\n","import shutil\n","import random\n","import numpy as np"],"metadata":{"id":"C6n5DE-AAipG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Set-up directory\n","os.chdir('/content/drive/My Drive/Colab Notebooks')"],"metadata":{"id":"wishyPO_Aivc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Function for data split\n","def split_data_into_train_val_test(image_folder, train_ratio=0.7, val_ratio=0.15):\n","    # Get a list of all subfolders (classes)\n","    class_folders = os.listdir(image_folder)\n","\n","    #Create train, validation and test directories ,inside the input directory, if they don't exist\n","    train_folder = os.path.join(image_folder, 'train')\n","    val_folder = os.path.join(image_folder, 'val')\n","    test_folder = os.path.join(image_folder, 'test')\n","    os.makedirs(train_folder, exist_ok=True)\n","    os.makedirs(val_folder, exist_ok=True)\n","    os.makedirs(test_folder, exist_ok=True)\n","\n","    #Split the data and copy images to the corresponding folders (not just moving the images)\n","    #The script splits each class folder into training, validation, and testing subsets while ensuring stratified sampling. This prevents one class from dominating one split.\n","    #It properly splits the images within each class according to the specified ratios (70%, 15%, 15%) and ensures that the distribution of each class is preserved in each subset.\n","    #Shuffling is also used to introduce randomness into the order of the samples within a class before splitting. This helps prevent any potential biases that might arise due to the order of images in the original dataset.\n","    for class_folder in class_folders:\n","        class_path = os.path.join(image_folder, class_folder)\n","        class_images = os.listdir(class_path)\n","        random.shuffle(class_images)\n","\n","        train_size = int(train_ratio * len(class_images))\n","        val_size = int(val_ratio * len(class_images))\n","        train_images = class_images[:train_size]\n","        val_images = class_images[train_size:train_size + val_size]\n","        test_images = class_images[train_size + val_size:]\n","\n","        #Create class subdirectories in train, validation and test folders\n","        train_class_folder = os.path.join(train_folder, class_folder)\n","        val_class_folder = os.path.join(val_folder, class_folder)\n","        test_class_folder = os.path.join(test_folder, class_folder)\n","        os.makedirs(train_class_folder, exist_ok=True)\n","        os.makedirs(val_class_folder, exist_ok=True)\n","        os.makedirs(test_class_folder, exist_ok=True)\n","\n","        #Copy images to the corresponding train, validation, and test subdirectories\n","        for train_image in train_images:\n","            src_path = os.path.join(class_path, train_image)\n","            dst_path = os.path.join(train_class_folder, train_image)\n","            shutil.copy(src_path, dst_path)\n","\n","        for val_image in val_images:\n","            src_path = os.path.join(class_path, val_image)\n","            dst_path = os.path.join(val_class_folder, val_image)\n","            shutil.copy(src_path, dst_path)\n","\n","        for test_image in test_images:\n","            src_path = os.path.join(class_path, test_image)\n","            dst_path = os.path.join(test_class_folder, test_image)\n","            shutil.copy(src_path, dst_path)\n"],"metadata":{"id":"_-42gmkWAxPA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["preprocessed_folder_path = '/content/drive/My Drive/Colab Notebooks/Preprocessed_Images'"],"metadata":{"id":"Ld0zuhKUAxSL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Split data into train and test and validation sets\n","split_data_into_train_val_test(preprocessed_folder_path)"],"metadata":{"id":"jv3AuW_WBAZA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"c7MCAyx2AxVj"},"execution_count":null,"outputs":[]}]}